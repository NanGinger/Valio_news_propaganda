import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# Download the stopwords dataset if not already downloaded
import nltk
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context
nltk.download('stopwords')

# Read text data from the TXT file
input_file_path = 'valio2.txt'
output_file_path = 'processed_text.txt'

with open(input_file_path, 'r', encoding='utf-8') as file:
    text_data = file.read()

# Define a set of stopwords
stop_words = set(stopwords.words('english'))

# Tokenize the text into words
words = word_tokenize(text_data)

# Remove stopwords, punctuation, and numbers
filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]

# Join the remaining words into a processed text
processed_text = ' '.join(filtered_words)

# Save the processed text to a new TXT file
with open(output_file_path, 'w', encoding='utf-8') as output_file:
    output_file.write(processed_text)

print(f'Text has been successfully processed and saved to {output_file_path}')
